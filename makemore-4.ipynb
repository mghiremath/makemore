{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "8bfc8c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "91df073c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in all the words\n",
    "words = open('names.txt', 'r').read().splitlines()\n",
    "words[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "1f1ed7d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32033"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "45828fd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n",
      "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n"
     ]
    }
   ],
   "source": [
    "# build vocabulary of characters and mappings to/from integers\n",
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i+1 for i,s in enumerate(chars) }\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s, i in stoi.items()}\n",
    "vocab_size = len(itos)\n",
    "print(vocab_size)\n",
    "print(itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "bd336ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182625, 3]) torch.Size([182625])\n",
      "torch.Size([22655, 3]) torch.Size([22655])\n",
      "torch.Size([22866, 3]) torch.Size([22866])\n"
     ]
    }
   ],
   "source": [
    "# build the dataset\n",
    "block_size = 3  # how many characters to predict\n",
    "\n",
    "def build_dataset(words):\n",
    "    X, Y = [], []\n",
    "\n",
    "    for w in words:\n",
    "        context = [0] * block_size\n",
    "        for ch in w + '.':\n",
    "            ix = stoi[ch]\n",
    "            X.append(context) # append the context\n",
    "            Y.append(ix) # append the next character\n",
    "            context = context[1:] + [ix] # crop and append the new character\n",
    "\n",
    "    X = torch.tensor(X)\n",
    "    Y = torch.tensor(Y)\n",
    "    print(X.shape, Y.shape)\n",
    "    return X, Y\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "random.shuffle(words)  # shuffle the words to get a good mix\n",
    "n1 = int(0.8 * len(words))  # 80% for training\n",
    "n2 = int(0.9 * len(words)) # 10% for validation\n",
    "\n",
    "Xtrain, Ytrain = build_dataset(words[:n1])\n",
    "Xdev, Ydev = build_dataset(words[n1:n2])\n",
    "Xtest, Ytest = build_dataset(words[n2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "e2115095",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function- we will use later when comparing manual gradients to PyTorch gradients\n",
    "def cmp(s, dt, t):\n",
    "    ex = torch.all(dt == t.grad).item()  # compare the gradients (dt - we calculated, t.grad - PyTorch calculated)\n",
    "    app = torch.allclose(dt, t.grad)  # approximate the gradients, by default, close if |a - b| < 1e-5 (relative & absolute)\n",
    "    maxdiff = (dt - t.grad).abs().max().item()  # find the maximum difference\n",
    "    print(f'{s:15s} | exact: {str(ex):5s} | approximate: {str(app):5s} | maxdiff: {maxdiff}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "163eeb6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([27, 10])\n",
      "Number of parameters: 4137\n"
     ]
    }
   ],
   "source": [
    "# MLP revisited\n",
    "n_embd = 10  # embedding dimension\n",
    "n_hidden = 64  # no. of neurons in the hidden layer\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647)  # for reproducibility\n",
    "C = torch.randn((vocab_size, n_embd)                    , generator=g)                                # embedding matrix\n",
    "\n",
    "print(C.shape)\n",
    "#Layer 1\n",
    "fan_in = n_embd * block_size                                                                          # number of input units\n",
    "W1 = torch.randn((fan_in, n_hidden)        , generator=g) * ((5/3) / (fan_in ** 0.5))                 # weights initialized to small values to avoid bias in the initial loss\n",
    "b1 = torch.randn(n_hidden                               , generator=g) * 0.01                        # useless cz of the batch norm. bias initialized to small values to avoid bias in the initial loss\n",
    "# Layer 2\n",
    "W2 = torch.randn((n_hidden, vocab_size)                 , generator=g) * 0.01                         # weights initialized to small values because we want to avoid bias in the initial loss\n",
    "b2 = torch.randn(vocab_size                             , generator=g) * 0                            # bias initialized to zero becasue we want to avoid bias in the initial loss\n",
    "# Batch normalization parameters\n",
    "bngain = torch.ones(1, n_hidden)*0.1 + 1.0  # batch normalization gain\n",
    "bnbias = torch.zeros(1, n_hidden)*0.1  # batch normalization bias\n",
    "\n",
    "# Note: Initializing many of these parameters in non-standard ways because\n",
    "#       sometimes initializing with e.g. all zeros could mask an incorrect \n",
    "#       implementation of the backward pass.\n",
    "\n",
    "parameters = [C, W1, b1, W2, b2, bngain, bnbias]  # list of all parameters\n",
    "print(f\"Number of parameters: {sum(p.nelement() for p in parameters)}\")\n",
    "for p in parameters:\n",
    "    p.requires_grad = True  # enable gradient computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "d87dbe6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3]) torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "n = batch_size # a shorter variable also, for convenience\n",
    "# construct a minibatch\n",
    "ix = torch.randint(0, Xtrain.shape[0], (batch_size,), generator=g)\n",
    "Xb, Yb = Xtrain[ix], Ytrain[ix] # batch X,Y\n",
    "print(Xb.shape, Yb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "5f0fbab0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.2870, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# forward pass, \"chunkated\" into smaller steps that are possible to backward one at a time\n",
    "emb = C[Xb]  # embed the characters into vectors shape - (n, block_size, n_embd), 32 examples, 3 characters, each have 10 embedded dimensions\n",
    "embcat = emb.view(emb.shape[0], -1)                  # concatenate the vectors, shape - (n, block_size * n_embd)\n",
    "# Linear layer 1\n",
    "hprebn = embcat @ W1 + b1  # hidden layer pre-activation(prebatch norm), shape - (n, n_hidden)\n",
    "\n",
    "# manual Batch norm layer - forward pass -  we can now inspect and compare intermediate gradients at every stage\n",
    "bnmeani = 1/n*hprebn.sum(0, keepdim=True)  \n",
    "bndiff = hprebn - bnmeani\n",
    "bndiff2 = bndiff**2\n",
    "bnvar = 1/(n-1)*(bndiff2).sum(0, keepdim=True) # note: Bessels correction: 1/n instead of 1/(n-1)\n",
    "bnvar_inv = (bnvar + 1e-5)**-0.5  # add a small number to ensure stability\n",
    "bnraw = bndiff * bnvar_inv # raw batch norm\n",
    "hpreact = bngain * bnraw + bnbias\n",
    "\n",
    "# Non-linearity\n",
    "h = torch.tanh(hpreact)  # hidden layer post-activation\n",
    "# Linear layer 2\n",
    "logits = h @ W2 + b2  # output layer - raw scores (logits) for each token in vocabulary\n",
    "\n",
    "\n",
    "# Cross-entropy loss (same as F.cross_entropy(logits, Yb))\n",
    "logit_maxes = logits.max(1, keepdim=True).values # If logits are large (e.g., [1000, 1001, 1002]), exp() can overflow & Subtracting the max doesn’t change softmax output, but avoids explosion\n",
    "norm_logits = logits - logit_maxes  # shape (n, vocab_size)\n",
    "counts = norm_logits.exp() # Exponentiate to Get Raw Softmax Numerators\n",
    "counts_sum = counts.sum(1, keepdim=True) # shape (n, 1) \n",
    "counts_sum_inv = counts_sum**-1 # if we use (1.0 / counts_sum) instead then we can't get backprop to be bit exact.\n",
    "probs = counts * counts_sum_inv # probs[i][j] = softmax(logits[i])[j]\n",
    "logprobs = probs.log()\n",
    "loss = -logprobs[range(n), Yb].mean() # range(n) gives row indices, Yb is the list of true class indices(og-prob assigned to the correct class) for each row, mean over the batch\n",
    "\n",
    "# Pytorch backward pass\n",
    "for p in parameters:\n",
    "    p.grad = None\n",
    "for t in [logprobs, probs, counts, counts_sum, counts_sum_inv, norm_logits, logit_maxes, logits, h,\n",
    "          hpreact, bnraw, bnvar_inv, bnvar, bndiff2, bndiff, hprebn, bnmeani, embcat, emb]:\n",
    "    t.retain_grad()\n",
    "loss.backward()\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "74feaf92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 10]) torch.Size([27, 10]) torch.Size([32, 3])\n",
      "tensor([[ 1,  1,  4],\n",
      "        [18, 14,  1],\n",
      "        [11,  5,  9],\n",
      "        [ 0,  0,  1],\n",
      "        [12, 15, 14]])\n"
     ]
    }
   ],
   "source": [
    "# emb = C[Xb]  # embed the characters into vectors shape - (n, block_size, n_embd)\n",
    "print(emb.shape, C.shape, Xb.shape)\n",
    "print(Xb[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dffeed2d",
   "metadata": {},
   "source": [
    "- Lookup embeddings for input batch Xb → shape: (n, block_size, n_embd)\n",
    "\n",
    "emb = C[Xb]\n",
    "\n",
    "- Flatten the last two dims into a single vector → shape: (n, block_size * n_embd)\n",
    "\n",
    "embcat = emb.view(n, -1)\n",
    "\n",
    "- First linear layer (affine transformation) → shape: (n, n_hidden)\n",
    "\n",
    "hprebn = embcat @ W1 + b1\n",
    "\n",
    "- Compute batch mean for batchnorm → shape: (1, n_hidden)\n",
    "\n",
    "bnmeani = 1/n * hprebn.sum(0, keepdim=True)\n",
    "\n",
    "- Subtract batch mean → mean-centered values\n",
    "\n",
    "bndiff = hprebn - bnmeani\n",
    "\n",
    "- Square the centered values\n",
    "\n",
    "bndiff2 = bndiff ** 2\n",
    "\n",
    "- Compute variance (with Bessel’s correction) → shape: (1, n_hidden)\n",
    "\n",
    "bnvar = 1/(n - 1) * bndiff2.sum(0, keepdim=True)\n",
    "\n",
    "- Inverse sqrt of variance for normalization (add epsilon for stability)\n",
    "\n",
    "bnvar_inv = (bnvar + 1e-5) ** -0.5\n",
    "\n",
    "- Normalize the centered values → shape: (n, n_hidden)\n",
    "\n",
    "bnraw = bndiff * bnvar_inv\n",
    "\n",
    "- Scale and shift using learned parameters (gamma and beta)\n",
    "\n",
    "hpreact = bngain * bnraw + bnbias\n",
    "\n",
    "- Apply non-linearity (tanh activation)\n",
    "\n",
    "h = torch.tanh(hpreact)\n",
    "\n",
    "- Second linear layer → raw scores (logits) for each class\n",
    "\n",
    "logits = h @ W2 + b2\n",
    "\n",
    "- Subtract max logit value for numerical stability (softmax trick)\n",
    "\n",
    "logit_maxes = logits.max(1, keepdim=True).values\n",
    "norm_logits = logits - logit_maxes\n",
    "\n",
    "- Exponentiate the normalized logits\n",
    "\n",
    "counts = norm_logits.exp()\n",
    "\n",
    "- Sum of exponentiated values across vocab dimension\n",
    "\n",
    "counts_sum = counts.sum(1, keepdim=True)\n",
    "\n",
    "- Invert the sum to use in softmax denominator\n",
    "\n",
    "counts_sum_inv = counts_sum ** -1\n",
    "\n",
    "- Calculate softmax probabilities\n",
    "\n",
    "probs = counts * counts_sum_inv\n",
    "\n",
    "- Take log of probabilities\n",
    "\n",
    "logprobs = probs.log()\n",
    "\n",
    "- Compute negative log likelihood loss averaged over batch\n",
    "\n",
    "loss = -logprobs[range(n), Yb].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "6b7f29f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7faa84280fa0>"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(F.one_hot(logits.max(1).indices, num_classes=logits.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "aa8308d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logprobs        | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "probs           | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "counts_sum_inv  | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "counts_sum      | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "counts          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "norm_logits     | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "logit_maxes     | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "logits          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "h               | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "W2              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "b2              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "hpreact         | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bngain          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnbias          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnraw           | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnvar_inv       | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnvar           | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bndiff          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bndiff2         | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnmeani         | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "hprebn          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "embcat          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "W1              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "b1              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "emb             | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "C               | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Exercise 1: backprop through the whole thing manually, \n",
    "# backpropagating through exactly all of the variables \n",
    "# as they are defined in the forward pass above, one by one\n",
    "\n",
    "dlogprobs = torch.zeros_like(logprobs) # create an array of zeros with the same shape as logprobs\n",
    "dlogprobs[range(n), Yb] = -1.0/n \n",
    "\n",
    "dprobs = (1.0/probs) * dlogprobs # chain rule\n",
    "\n",
    "dcounts_sum_inv = (dprobs * counts).sum(1, keepdim=True) # sum along the first dimension to get the same shape as counts_sum_inv\n",
    "\n",
    "dcounts_sum = (-1.0 * counts_sum **-2) * dcounts_sum_inv\n",
    "\n",
    "dcounts = dprobs * counts_sum_inv + dcounts_sum.expand_as(counts)           #counts_sum[i][0] = sum(counts[i][:]), so ∂counts_sum[i][0] / ∂counts[i][j] = 1\n",
    "# dcounts = torch.ones_like(counts) * dcounts_sum \n",
    "\n",
    "dnorm_logits = counts * dcounts\n",
    "\n",
    "dlogits = dnorm_logits.clone()        # dlogits will be exact copy of norm_logits - refer book & not a final derivative of logits\n",
    "dlogit_maxes = (- dnorm_logits).sum(1, keepdim=True)    # similarly dlogit_maxes will be negative of dnorm-logits because of the sign. Since logit_maxes is a column \n",
    "                                                        #and since we keep replicating the same elements of logit_maxes(n, 1) across all the columns of logits (n, vocab_size), \n",
    "                                                        # these are all separate branches using one of the variable of logit_maxes - therefore in backward pass,  we have to do sum of along 1 in order not to destroy that (n, 1) dimensions\n",
    "\n",
    "#dlogit_maxes =  torch.zeros_like(logits)        # we need to scatter the max values at the right positions from where the max values came\n",
    "#dlogit_maxes[range(n), Yb] = 1\n",
    "dlogits += F.one_hot(logits.max(1).indices, num_classes=logits.shape[1]) * dlogit_maxes\n",
    "\n",
    "dh = dlogits @ W2.T\n",
    "dW2 = h.T @ dlogits\n",
    "db2 = dlogits.sum(0,keepdim=True)         # d=a*b+c, dL/da=dL/dd*b.T ; dL/db = a.T*dL/dd  ; dL/dc = dL/dd.sum(0)  - sum over the rows\n",
    "\n",
    "dhpreact =  (1 - h**2) * dh       # we know if a = tanh(z) ; da/dz = 1-a**2\n",
    "\n",
    "dbngain = (bnraw * dhpreact).sum(0, keepdim=True) # during forward pass, we multiplied bngain(1,64) with bnraw(32,64) across the rows. \n",
    "                                                    # and in backward pass, we multiply bnraw(32,64) with bhpreact(32,64) and sum across the rows to get dbngain(1,64).\n",
    "\n",
    "dbnraw = (bngain * dhpreact)\n",
    "dbnbias = dhpreact.sum(0, keepdim=True)\n",
    "\n",
    "\n",
    "dbnvar_inv = (bndiff * dbnraw).sum(0, keepdim=True)\n",
    "dbnvar = (-0.5 * (bnvar + 1e-5)**-1.5) * dbnvar_inv\n",
    "#dbndiff2 = (1.0/(n-1))*(torch.ones_like(bndiff2)) * dbnvar\n",
    "dbndiff2 = (1.0/(n-1)) * dbnvar\n",
    "\n",
    "\n",
    "dbndiff = (dbnraw * bnvar_inv) + (2.0*bndiff * dbndiff2)\n",
    "\n",
    "# Broadcasting in the forward pass means  a variable reuse and therefore there will be a sum in the backward pass\n",
    "dhprebn = dbndiff.clone() # both bndiff and hprebn have the same shape, then local derivatives are equal to 1.0 - simply the gradient copies from dhprebn to dbndiff.\n",
    "#dbmeani = (- torch.ones_like(bndiff) * dbndiff).sum(0, keepdim=True)\n",
    "dbnmeani = (-dbndiff).sum(0, keepdim=True)\n",
    "\n",
    "dhprebn += 1.0/n * (torch.ones_like(hprebn) * dbnmeani)       # scaling and broadcasting because of the sum over rows in forward pass\n",
    "\n",
    "dembcat = dhprebn @ W1.T\n",
    "dW1 = embcat.T @ dhprebn\n",
    "db1 = dhprebn.sum(0)\n",
    "demb = dembcat.view(emb.shape)\n",
    "\n",
    "# Reset the derivative of the embedding matrix C to zero before accumulating new derivatives.\n",
    "# This is necessary because in PyTorch, derivatives accumulate by default (i.e., they don't auto-zero after each backward pass).\n",
    "dC = torch.zeros_like(C)                       \n",
    "for j in range(n):                                                       # Loop over each item in the batch (there are 'n' examples in total, e.g., 32 if batch size is 32)\n",
    "    for k in range(block_size):                                          # Loop over each token in the input block (e.g., 3 tokens per input if block_size = 3)\n",
    "        ix = Xb[j, k]                                                    # Get the index of the k-th token in the j-th example. This index refers to a row in the embedding matrix C.\n",
    "        dC[ix] += demb[j, k]                                             # Accumulate the derivative for token 'ix' into the corresponding row of dC. demb[j][k] is the derivative of the loss w.r.t. C[ix], so we add it to that row.\n",
    "                                                                         # If the same token appears multiple times in the batch, this adds up all their contributions.\n",
    "\n",
    "\n",
    "cmp('logprobs', dlogprobs, logprobs)\n",
    "cmp('probs', dprobs, probs)\n",
    "cmp('counts_sum_inv', dcounts_sum_inv, counts_sum_inv)\n",
    "cmp('counts_sum', dcounts_sum, counts_sum)\n",
    "cmp('counts', dcounts, counts)\n",
    "cmp('norm_logits', dnorm_logits, norm_logits)\n",
    "cmp('logit_maxes', dlogit_maxes, logit_maxes)\n",
    "cmp('logits', dlogits, logits)\n",
    "cmp('h', dh, h)\n",
    "cmp('W2', dW2, W2)\n",
    "cmp('b2', db2, b2)\n",
    "cmp('hpreact', dhpreact, hpreact)\n",
    "cmp('bngain', dbngain, bngain)\n",
    "cmp('bnbias', dbnbias, bnbias)\n",
    "cmp('bnraw', dbnraw, bnraw)\n",
    "cmp('bnvar_inv', dbnvar_inv, bnvar_inv)\n",
    "cmp('bnvar', dbnvar, bnvar)\n",
    "cmp('bndiff', dbndiff, bndiff)\n",
    "cmp('bndiff2', dbndiff2, bndiff2)\n",
    "cmp('bnmeani', dbnmeani, bnmeani)\n",
    "cmp('hprebn', dhprebn, hprebn)\n",
    "cmp('embcat', dembcat, embcat)\n",
    "cmp('W1', dW1, W1)\n",
    "cmp('b1', db1, b1)\n",
    "cmp('emb', demb, emb)\n",
    "cmp('C', dC, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "01e6cf40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.2870399951934814 diff: 2.384185791015625e-07\n"
     ]
    }
   ],
   "source": [
    "# Forward pass of cross-entropy loss\n",
    "# before:\n",
    "# logit_maxes = logits.max(1, keepdim=True).values\n",
    "# norm_logits = logits - logit_maxes # subtract max for numerical stability\n",
    "# counts = norm_logits.exp()\n",
    "# counts_sum = counts.sum(1, keepdims=True)\n",
    "# counts_sum_inv = counts_sum**-1 # if I use (1.0 / counts_sum) instead then I can't get backprop to be bit exact...\n",
    "# probs = counts * counts_sum_inv\n",
    "# logprobs = probs.log()\n",
    "# loss = -logprobs[range(n), Yb].mean()\n",
    "# after:\n",
    "loss_fast = F.cross_entropy(logits, Yb)\n",
    "print(loss_fast.item(), 'diff:', (loss_fast - loss).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "d9ac70ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits          | exact: False | approximate: True  | maxdiff: 1.1059455573558807e-08\n"
     ]
    }
   ],
   "source": [
    "# Backward pass of cross-entropy loss\n",
    "\n",
    "dlogits = F.softmax(logits, dim=1) # softmax along the rows left to right\n",
    "dlogits [range(n), Yb] -= 1      # at the right positions, subtract 1. \n",
    "dlogits /=n                      # divide by n to scale down the gradient by n.\n",
    "\n",
    "cmp('logits', dlogits, logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7aa3e0e",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "source": [
    "Intuitively, `dlogits` represents the gradient of the loss with respect to the logits (the raw output scores before softmax) for each example in your batch.\n",
    "\n",
    "- It tells you how much you need to change each logit to decrease the loss.\n",
    "- In classification, if the predicted probability for the correct class is too low, the corresponding entry in `dlogits` will be negative (indicating you should increase that logit).\n",
    "- For incorrect classes, the gradient will be positive or zero, suggesting you should decrease those logits.\n",
    "\n",
    "In summary:  \n",
    "**`dlogits` shows the direction and amount to nudge each logit to make the model's predictions better (i.e., to reduce the loss).**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83619dcb",
   "metadata": {},
   "source": [
    "- The logit is the probabilities matrix in the forward pass before the softmax. In below plot black squares are the positions of the correct indices where we subtracted a 1.\n",
    "- If we take the first row of probabilities (softmax), and the derivative dlogits' first row (multiplied by n to make everything interpretable), both are exaclty same except the position of the correct index (which is ~-1)\n",
    "- If we take sum of first row of dlogits (dlogits[0].sum()), we can see below it is ~0. THis is because the fabric of probabilities of correct index and wrong indices are in the opposite directions. 1 is pushing up and all others are pulling down. This is equalized becasue the sum is zero. And eventually we get a tug on the weights and biases o that pulley mechanism. In each update, we tug in the direction we like and the parameters are giving in to the tug.\n",
    "- The force we are applying is proportional to the probabilities that came out in forward pass. For example, if our probs came out exactly correct, there would only be one 1 at correct position and all others exactly zeroes. No push and pull.\n",
    "- The amount ehihc our prediction is incorrect is exactly the amount by which we're going to get a pull or push in that dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "96870d35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 27]), torch.Size([32]))"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape, Yb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "a347edd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0399, 0.0414, 0.0350, 0.0391, 0.0355, 0.0402, 0.0353, 0.0369, 0.0347,\n",
       "        0.0373, 0.0376, 0.0381, 0.0372, 0.0368, 0.0379, 0.0338, 0.0325, 0.0356,\n",
       "        0.0345, 0.0385, 0.0386, 0.0360, 0.0359, 0.0403, 0.0389, 0.0364, 0.0361],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(logits, dim=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "3d38c931",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0399,  0.0414,  0.0350,  0.0391,  0.0355,  0.0402,  0.0353,  0.0369,\n",
       "        -0.9653,  0.0373,  0.0376,  0.0381,  0.0372,  0.0368,  0.0379,  0.0338,\n",
       "         0.0325,  0.0356,  0.0345,  0.0385,  0.0386,  0.0360,  0.0359,  0.0403,\n",
       "         0.0389,  0.0364,  0.0361], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlogits[0] * n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "3778e7b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9.3132e-10, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlogits[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "719bc7e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7faa909ae4f0>"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(dlogits.detach(), cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "fa610501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max diff:  tensor(4.7684e-07, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "# Forward pass of BatchNorm layer\n",
    "# before:\n",
    "# bnmeani = 1/n*hprebn.sum(0, keepdim=True) = hprebn.mean(0, keepdim=True)\n",
    "# bndiff = hprebn - bnmeani = hprebn - hprebn.mean(0, keepdim=True)\n",
    "# bndiff2 = bndiff**2\n",
    "# bnvar = 1/(n-1)*(bndiff2).sum(0, keepdim=True) # note: Bessel's correction (dividing by n-1, not n) = hprebn.var(0, keepdim=True, unbiased=True)\n",
    "# bnvar_inv = (bnvar + 1e-5)**-0.5 = 1.0/torch.sqrt(bnvar + 1e-5)\n",
    "# bnraw = bndiff * bnvar_inv = (hprebn - hprebn.mean(0, keepdim=True)))/torch.sqrt(bnvar + 1e-5)\n",
    "# hpreact = bngain * bnraw + bnbias = bngain * (hprebn - hprebn.mean(0, keepdim=True))/torch.sqrt(bnvar + 1e-5) + bnbias\n",
    "\n",
    "# now:\n",
    "hpreact_fast = bngain * (hprebn - hprebn.mean(0, keepdim=True))/torch.sqrt(hprebn.var(0, keepdim=True, unbiased=True) + 1e-5) + bnbias\n",
    "print('max diff: ', (hpreact_fast - hpreact).abs().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "33a7e0d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hprebn          | exact: False | approximate: True  | maxdiff: 5.820766091346741e-11\n"
     ]
    }
   ],
   "source": [
    "# Backward pass of BatchNorm layer\n",
    "\n",
    "# before we had:\n",
    "# dbnraw = bngain * dhpreact \n",
    "# dbndiff = bnvar_inv * dbnraw = bnvar_inv * bngain * dhpreact\n",
    "# dbnvar_inv = (bndiff * dbnraw).sum(0, keepdim=True) = ((hprebn - bnmeani) * (bngain * dhpreact)).sum(0, keepdim=True) #from forward pass\n",
    "# dbnvar = (-0.5*(bnvar + 1e-5)**-1.5) * dbnvar_inv = (-0.5*(bnvar + 1e-5)**-1.5) * ((hprebn - bnmeani) * (bngain * dhpreact)).sum(0, keepdim=True)\n",
    "# dbndiff2 = (1.0/(n-1))*torch.ones_like(bndiff2) * dbnvar = (1.0/(n-1)) * dbnvar\n",
    "# dbndiff += (2*bndiff) * dbndiff2 = (2*(hprebn - bnmeani)) * dbndiff2 \n",
    "# Total dbndiff = bnvar_inv * bngain * dhpreact + (2*(hprebn - bnmeani)) * dbndiff2 \n",
    "#               = bngain * bnvar_inv * dhpreact + dbndiff2 * (2*(hprebn - bnmeani))\n",
    "#               = bngain * bnvar_inv * dhpreact + ((1.0/(n-1)) * dbnvar) * (2*(hprebn - bnmeani))\n",
    "#               = bngain * bnvar_inv * dhpreact + ((1.0/(n-1)) * (-0.5*(bnvar + 1e-5)**-1.5) * ((hprebn - bnmeani) * (bngain * dhpreact)).sum(0, keepdim=True)) * (2*(hprebn - bnmeani))\n",
    "#               = bngain * bnvar_inv * dhpreact - (1/(n-1)) * (hprebn - bnmeani) * ((bnvar + 1e-5)**-1.5) * ((hprebn - bnmeani) * (bngain * dhpreact)).sum(0, keepdim=True))\n",
    "# dhprebn = dbndiff.clone()         \n",
    "# dbnmeani = (-dbndiff).sum(0) \n",
    "# dhprebn += 1.0/n * (torch.ones_like(hprebn) * dbnmeani) \n",
    "# Total dhprebn = dbndiff + 1.0/n * dbnmeani) = dbndiff - 1.0/n * dbndiff.sum(0) \n",
    "#               = [bngain * bnvar_inv * dhpreact - (1/(n-1)) * (hprebn - bnmeani) * ((bnvar + 1e-5)**-1.5) * ((hprebn - bnmeani) * (bngain * dhpreact)).sum(0, keepdim=True))] - 1.0/n * [bngain * bnvar_inv * dhpreact - (1/(n-1)) * (hprebn - bnmeani) * ((bnvar + 1e-5)**-1.5) * ((hprebn - bnmeani) * (bngain * dhpreact)).sum(0, keepdim=True))].sum(0)\n",
    "#               Let A = bngain * bnvar_inv * dhpreact\n",
    "#\t            \tB = (1 / (n-1)) * (hprebn - bnmeani) * (bnvar + 1e-5)**-1.5 * ((hprebn - bnmeani) * (bngain * dhpreact)).sum(0)             \n",
    "#               dhprebn = A - B - (1/n) * (A - B).sum(0)\n",
    "#                       = A - B - (1/n) * A.sum(0) + (1/n) * B.sum(0)\n",
    "#                       = A - (1/n) * A.sum(0) - B + (1/n) * B.sum(0)\n",
    "#                       = bngain*bnvar_inv/n * (n*dhpreact - dhpreact.sum(0) - n/(n-1)*bnraw*(dhpreact*bnraw).sum(0))   # expanding and factoring above equation\n",
    "# calculate dhprebn given dhpreact (i.e. backprop through the batchnorm)\n",
    "# (you'll also need to use some of the variables from the forward pass up above)\n",
    "\n",
    "dhprebn = bngain*bnvar_inv/n * (n*dhpreact - dhpreact.sum(0) - n/(n-1)*bnraw*(dhpreact*bnraw).sum(0))\n",
    "cmp('hprebn', dhprebn, hprebn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "b150dc2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([27, 10])\n",
      "Number of parameters: 12297\n",
      "      0/ 200000: 3.3157\n",
      "  10000/ 200000: 2.1739\n",
      "  20000/ 200000: 2.2650\n",
      "  30000/ 200000: 2.3968\n",
      "  40000/ 200000: 1.9447\n",
      "  50000/ 200000: 2.4589\n",
      "  60000/ 200000: 2.5885\n",
      "  70000/ 200000: 2.0133\n",
      "  80000/ 200000: 2.3359\n",
      "  90000/ 200000: 2.1335\n",
      " 100000/ 200000: 2.0120\n",
      " 110000/ 200000: 2.3745\n",
      " 120000/ 200000: 2.0171\n",
      " 130000/ 200000: 2.5168\n",
      " 140000/ 200000: 2.4345\n",
      " 150000/ 200000: 2.2161\n",
      " 160000/ 200000: 2.0581\n",
      " 170000/ 200000: 1.8481\n",
      " 180000/ 200000: 2.2266\n",
      " 190000/ 200000: 1.7829\n"
     ]
    }
   ],
   "source": [
    "# Exercise 4: putting it all together!\n",
    "# Train the MLP neural net with your own backward pass\n",
    "\n",
    "# init\n",
    "n_embd = 10 # the dimensionality of the character embedding vectors\n",
    "n_hidden = 200 # the number of neurons in the hidden layer of the MLP\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647)  # for reproducibility\n",
    "C = torch.randn((vocab_size, n_embd)                    , generator=g)                                # embedding matrix\n",
    "\n",
    "print(C.shape)\n",
    "#Layer 1\n",
    "fan_in = n_embd * block_size                                                                          # number of input units\n",
    "W1 = torch.randn((fan_in, n_hidden)        , generator=g) * ((5/3) / (fan_in ** 0.5))                 # weights initialized to small values to avoid bias in the initial loss\n",
    "b1 = torch.randn(n_hidden                               , generator=g) * 0.01                        # useless cz of the batch norm. bias initialized to small values to avoid bias in the initial loss\n",
    "# Layer 2\n",
    "W2 = torch.randn((n_hidden, vocab_size)                 , generator=g) * 0.01                         # weights initialized to small values because we want to avoid bias in the initial loss\n",
    "b2 = torch.randn(vocab_size                             , generator=g) * 0                            # bias initialized to zero becasue we want to avoid bias in the initial loss\n",
    "# Batch normalization parameters\n",
    "bngain = torch.ones(1, n_hidden)*0.1 + 1.0  # batch normalization gain\n",
    "bnbias = torch.zeros(1, n_hidden)*0.1  # batch normalization bias\n",
    "\n",
    "# Note: Initializing many of these parameters in non-standard ways because\n",
    "#       sometimes initializing with e.g. all zeros could mask an incorrect \n",
    "#       implementation of the backward pass.\n",
    "\n",
    "parameters = [C, W1, b1, W2, b2, bngain, bnbias]  # list of all parameters\n",
    "print(f\"Number of parameters: {sum(p.nelement() for p in parameters)}\")\n",
    "for p in parameters:\n",
    "    p.requires_grad = True  # enable gradient computation for these parameters\n",
    "\n",
    "\n",
    "# same optimization as last time\n",
    "max_steps = 200000\n",
    "batch_size = 32\n",
    "n = batch_size # convenience\n",
    "lossi = []\n",
    "\n",
    "# use this context manager for efficiency once your backward pass is written (TODO)\n",
    "with torch.no_grad():\n",
    "    # kick off optimization\n",
    "  for i in range(max_steps):\n",
    "     # minibatch construct\n",
    "    ix = torch.randint(0, Xtrain.shape[0], (batch_size,), generator=g)\n",
    "    Xb, Yb = Xtrain[ix], Ytrain[ix] # batch X,Y\n",
    "\n",
    "    # forward pass\n",
    "    emb = C[Xb] # embed the characters into vectors\n",
    "    embcat = emb.view(emb.shape[0], -1) # concatenate the vectors\n",
    "    # Linear layer\n",
    "    hprebn = embcat @ W1 + b1 # hidden layer pre-activation\n",
    "    # manual Batch norm layer - forward pass -  we can now inspect and compare intermediate gradients at every stage\n",
    "    # -------------------------------------------------------------\n",
    "    bnmean = hprebn.mean(0, keepdim=True)\n",
    "    bnvar = hprebn.var(0, keepdim=True, unbiased=True)\n",
    "    bnvar_inv = (bnvar + 1e-5)**-0.5\n",
    "    bnraw = (hprebn - bnmean) * bnvar_inv\n",
    "    hpreact = bngain * bnraw + bnbias\n",
    "    # -------------------------------------------------------------\n",
    "    # Non-linearity\n",
    "    h = torch.tanh(hpreact) # hidden layer\n",
    "    logits = h @ W2 + b2 # output layer\n",
    "    loss = F.cross_entropy(logits, Yb) # loss function\n",
    "\n",
    "    # backward pass\n",
    "    for p in parameters:\n",
    "      p.grad = None\n",
    "    #loss.backward() # use this for correctness comparisons, delete it later!\n",
    "\n",
    "    # manual backprop! #swole_doge_meme\n",
    "    # -----------------\n",
    "    # Backward pass of cross-entropy loss\n",
    "\n",
    "    dlogits = F.softmax(logits, dim=1) # softmax along the rows left to right\n",
    "    dlogits [range(n), Yb] -= 1      # at the right positions, subtract 1. \n",
    "    dlogits /=n                      # divide by n to scale down the gradient by n.\n",
    "\n",
    "    # 2nd layer backprop\n",
    "    dh = dlogits @ W2.T\n",
    "    dW2 = h.T @ dlogits\n",
    "    db2 = dlogits.sum(0)         # d=a*b+c, dL/da=dL/dd*b.T ; dL/db = a.T*dL/dd  ; dL/dc = dL/dd.sum(0)  - sum over the rows\n",
    "\n",
    "    # Tanh layer\n",
    "    dhpreact =  (1 - h**2) * dh       # we know if a = tanh(z) ; da/dz = 1-a**2\n",
    "\n",
    "    # batchnorm layer backprop\n",
    "    dbngain = (bnraw * dhpreact).sum(0, keepdim=True)\n",
    "    dbnbias = dhpreact.sum(0, keepdim=True)\n",
    "    dhprebn = bngain*bnvar_inv/n * (n*dhpreact - dhpreact.sum(0) - n/(n-1)*bnraw*(dhpreact*bnraw).sum(0))\n",
    "\n",
    "    # linear layerdembcat = dhprebn @ W1.T\n",
    "    dW1 = embcat.T @ dhprebn\n",
    "    db1 = dhprebn.sum(0)\n",
    "    demb = dembcat.view(emb.shape)\n",
    "    dC = torch.zeros_like(C)                       \n",
    "    for j in range(n):                                                       # Loop over each item in the batch (there are 'n' examples in total, e.g., 32 if batch size is 32)\n",
    "        for k in range(block_size):                                          # Loop over each token in the input block (e.g., 3 tokens per input if block_size = 3)\n",
    "            ix = Xb[j, k]                                                    # Get the index of the k-th token in the j-th example. This index refers to a row in the embedding matrix C.\n",
    "            dC[ix] += demb[j, k]                                             # Accumulate the derivative for token 'ix' into the corresponding row of dC. demb[j][k] is the derivative of the loss w.r.t. C[ix], so we add it to that row.\n",
    "                                                                             # If the same token appears multiple times in the batch, this adds up all their contributions.\n",
    "    # -----------------\n",
    "    grads = [dC, dW1, db1, dW2, db2, dbngain, dbnbias]\n",
    "\n",
    "    # update\n",
    "    lr = 0.1 if i < 100000 else 0.01 # step learning rate decay\n",
    "    for p, grad in zip(parameters, grads):\n",
    "      #p.data += -lr * p.grad # old way of cheems doge (using PyTorch grad from .backward())\n",
    "      p.data += -lr * grad # new way of swole doge TODO: enable\n",
    "    \n",
    "    # track stats\n",
    "    if i % 10000 == 0: # print every once in a while\n",
    "      print(f'{i:7d}/{max_steps:7d}: {loss.item():.4f}')\n",
    "    lossi.append(loss.log10().item())\n",
    "\n",
    "    #if i >= 100: # TODO: delete early breaking when you're ready to train the full net\n",
    "      #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "a9135ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# useful for checking your gradients\n",
    "# for p,g in zip(parameters, grads):\n",
    "#   cmp(str(tuple(p.shape)), g, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "02efe21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calibrate the batch norm at the end of the training - \n",
    "# this calculates and sets the batch mean and standard deviation a single timeover the training set\n",
    "\n",
    "with torch.no_grad():\n",
    "    # pass the training set through\n",
    "    emb = C[Xtrain]\n",
    "    embcat = emb.view(emb.shape[0], -1)\n",
    "    hpreact = embcat @ W1 #+ b1 # get the preactivation for every example\n",
    "    # measure the mean/std over the entire training set\n",
    "    bnmean = hpreact.mean(0, keepdim=True)\n",
    "    bnvar = hpreact.var(0, keepdim=True, unbiased=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "10d366f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 2.4859\n",
      "val loss: 2.5557\n"
     ]
    }
   ],
   "source": [
    "# evaluate train and val loss\n",
    "\n",
    "@torch.no_grad() # decorator disable gradient computation for evaluation\n",
    "def split_loss(split):\n",
    "    x,y = {\n",
    "        'train': (Xtrain, Ytrain),\n",
    "        'val': (Xdev, Ydev),\n",
    "        'test': (Xtest, Ytest)\n",
    "    } [split] # get the data for the split\n",
    "    emb = C[x] # embedding lookup - (N, block_size, n_embd)\n",
    "    embcat = emb.view(emb.shape[0], -1) # concat into (N, block_size * n_embd)\n",
    "    hpreact = embcat @ W1 + b1 # hidden layer pre-activation\n",
    "    #hpreact = bngain * (hpreact - hpreact.mean(0, keepdim=True)) / (hpreact.std(0, keepdim=True) + 1e-5) + bnbias # take every single neuron and its exact firing rate will be exaclty unit gaussian\n",
    "    hpreact = bngain * (hpreact - bnmean) / (bnvar + 1e-5)**-0.5 + bnbias # take every single neuron and its exact firing rate will be exaclty unit gaussian\n",
    "    h = torch.tanh(hpreact) # (N, n_hidden)\n",
    "    logits = h @ W2 + b2 # output layer (N, vocab_size)\n",
    "    loss = F.cross_entropy(logits, y) # compute loss\n",
    "    print(f'{split} loss: {loss.item():.4f}')\n",
    "\n",
    "split_loss('train')\n",
    "split_loss('val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "263a8572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "junide\n",
      "jayckarous\n",
      "fay\n",
      "adin\n",
      "kai\n",
      "rono\n",
      "sabellee\n",
      "kalinaa\n",
      "zamilena\n",
      "jadeyaine\n",
      "amel\n",
      "sera\n",
      "evy\n",
      "artellarmunthif\n",
      "demij\n",
      "pontel\n",
      "jarsani\n",
      "cora\n",
      "yarion\n",
      "kaelandreed\n"
     ]
    }
   ],
   "source": [
    "# sample from the model\n",
    "g= torch.Generator().manual_seed(2147483647)  # for reproducibility\n",
    "\n",
    "for _ in range(20):\n",
    "    out = []\n",
    "    context = [0] * block_size  # start with a context of zeros\n",
    "    while True:\n",
    "        # ------------\n",
    "        # forward pass:\n",
    "        # Embedding\n",
    "        emb = C[torch.tensor([context])]  # get the embedding for the context\n",
    "        embcat = emb.view(emb.shape[0], -1) # concat into (N, block_size * n_embd)\n",
    "        hpreact = embcat @ W1 + b1\n",
    "        hpreact = bngain * (hpreact - bnmean) * (bnvar + 1e-5)**-0.5 + bnbias\n",
    "        h = torch.tanh(hpreact) # (N, n_hidden)\n",
    "        logits = h @ W2 + b2  # output layer\n",
    "        # ------------\n",
    "        # Sample\n",
    "        probs = F.softmax(logits, dim=1)  # convert to probabilities\n",
    "        ix = torch.multinomial(probs, num_samples=1, generator=g).item()  # sample from the distribution\n",
    "        if ix == 0: break  # stop if we hit the end token\n",
    "        out.append(itos[ix])  # append the character to the output\n",
    "        context = context[1:] + [ix]  # update the context\n",
    "\n",
    "    print(''.join(out))  # print the generated name"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
